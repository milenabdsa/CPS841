{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import wisardpkg as wp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import cv2\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import gist\n",
    "from math import ceil\n",
    "import random\n",
    "\n",
    "import itertools\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count) \n",
    "\n",
    "def clf_eval(name, y_true, y_pred, classes=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']):\n",
    "    clf_matrix = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    print(clf_matrix)\n",
    "    \n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img is not None:\n",
    "            #images.append(gist.extract(img))\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def import_data_sb(classes):\n",
    "  first = True\n",
    "  if \"Expiro\" in classes: #### VIRUS # EXPIRO\n",
    "    img = load_images_from_folder('malevis_train_val_224x224/train/Expiro')\n",
    "    if first: # FIRST?\n",
    "      length = len(img)\n",
    "      data = img\n",
    "      y = ['Expiro']*length\n",
    "      first = False\n",
    "    else:\n",
    "      data = np.concatenate((data, img), axis=0)\n",
    "      y = np.concatenate((y,['Expiro']*length),axis=0)\n",
    "    del img\n",
    "    gc.collect()\n",
    "\n",
    "  if \"Neshta\" in classes: #### VIRUS # NESHTA\n",
    "    img = load_images_from_folder('malevis_train_val_224x224/train/Neshta')\n",
    "    if first: # FIRST?\n",
    "      length = len(img)\n",
    "      data = img\n",
    "      y = ['Neshta']*length\n",
    "      first = False\n",
    "    else:\n",
    "      data = np.concatenate((data, img), axis=0)\n",
    "      y = np.concatenate((y,['Neshta']*length),axis=0)\n",
    "    del img\n",
    "    gc.collect()\n",
    "\n",
    "  if \"Sality\" in classes: #### VIRUS SALITY\n",
    "    img = load_images_from_folder('malevis_train_val_224x224/train/Sality')\n",
    "    if first: # FIRST?\n",
    "      length = len(img)\n",
    "      data = img\n",
    "      y = ['Sality']*length\n",
    "      first = False\n",
    "    else:\n",
    "      data = np.concatenate((data, img), axis=0)\n",
    "      y = np.concatenate((y,['Sality']*length),axis=0)\n",
    "    del img\n",
    "    gc.collect()\n",
    "\n",
    "  if \"VBA\" in classes: #### VIRUS VBA\n",
    "    img = load_images_from_folder('malevis_train_val_224x224/train/VBA')\n",
    "    if first: # FIRST?\n",
    "      length = len(img)\n",
    "      data = img\n",
    "      y = ['VBA']*length\n",
    "      first = False\n",
    "    else:\n",
    "      data = np.concatenate((data, img), axis=0)\n",
    "      y = np.concatenate((y,['VBA']*length),axis=0)\n",
    "    del img\n",
    "    gc.collect()\n",
    "\n",
    "  data = np.resize(data, (len(data),224*224))  \n",
    "\n",
    "  data = data.tolist()\n",
    "    \n",
    "  a = []\n",
    "  for count in range(len(data)):\n",
    "    a.append(count)\n",
    "\n",
    "  order = random.sample(a, len(data))  \n",
    "\n",
    "  data = [data[i] for i in order]\n",
    "  y = [y[i] for i in order]\n",
    " \n",
    "  X_lsb = []\n",
    "  X_msb = []\n",
    "\n",
    "  for i in range(len(data)):\n",
    "    X_lsb_current = []\n",
    "    X_msb_current = []\n",
    "    for k in range(len(data[0])):\n",
    "      binary = list('{0:0b}'.format(data[i][k]))\n",
    "      total = len(binary)\n",
    "      for j in range(8-total):\n",
    "        binary.insert(0,'0')\n",
    "      for j in range(8):\n",
    "        binary[j] = int(binary[j])\n",
    "\n",
    "      X_lsb_current.append(binary[3])\n",
    "      X_lsb_current.append(binary[2])\n",
    "      X_lsb_current.append(binary[1])\n",
    "      X_lsb_current.append(binary[0])\n",
    "      X_msb_current.append(binary[7])\n",
    "      X_msb_current.append(binary[6])\n",
    "      X_msb_current.append(binary[5])\n",
    "      X_msb_current.append(binary[4])\n",
    "\n",
    "    X_lsb.append(X_lsb_current)\n",
    "    X_msb.append(X_msb_current)\n",
    "    \n",
    "  del data\n",
    "  gc.collect()\n",
    "\n",
    "  split = ceil(len(y)*0.7)\n",
    "  X_traincv_lsb = X_lsb[0:split]\n",
    "  X_testcv_lsb = X_lsb[split::]\n",
    "  X_traincv_msb = X_msb[0:split]\n",
    "  X_testcv_msb = X_msb[split::]\n",
    "  y_traincv = y[0:split]\n",
    "  y_testcv = y[split::]\n",
    "\n",
    "  return X_traincv_lsb, X_testcv_lsb, X_traincv_msb, X_testcv_msb, y_traincv, y_testcv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WiSARD\n",
      "Training...\n",
      "Data imported\n"
     ]
    }
   ],
   "source": [
    "print(\"WiSARD\")\n",
    "\n",
    "bleachingActivated=True\n",
    "ignoreZero=False\n",
    "\n",
    "wsd_lsb  = wp.Wisard(20, bleachingActivated = bleachingActivated, ignoreZero = ignoreZero, verbose = False, returnActivationDegree=True,returnClassesDegrees=True)\n",
    "wsd_msb  = wp.Wisard(20, bleachingActivated = bleachingActivated, ignoreZero = ignoreZero, verbose = False, returnActivationDegree=True,returnClassesDegrees=True)\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "if True:\n",
    "    X_traincv_lsb, X_testcv_lsb, X_traincv_msb, X_testcv_msb, y_traincv, y_testcv = import_data_sb([\"Expiro\",\"Neshta\",\"Sality\",\"VBA\"])\n",
    "\n",
    "if False:\n",
    "    ds_lsb_train = wp.DataSet()\n",
    "    ds_msb_train = wp.DataSet()\n",
    "    ds_lsb_test = wp.DataSet()\n",
    "    ds_msb_test = wp.DataSet()\n",
    "\n",
    "    for i in len(X_traincv_lsb):\n",
    "        ds_lsb_train.add(wp.BinInput(X_traincv_lsb[i]), y_traincv[i])\n",
    "        ds_msb_train.add(wp.BinInput(X_traincv_msb[i]), y_traincv[i])\n",
    "\n",
    "    for i in len(X_testcv_lsb):\n",
    "        ds_lsb_test.add(wp.BinInput(X_testcv_lsb[i]), y_testcv[i])\n",
    "        ds_msb_test.add(wp.BinInput(X_testcv_msb[i]), y_testcv[i])\n",
    "\n",
    "    ds_lsb_train.save('lsb_train')\n",
    "    ds_msb_train.save('msb_train')\n",
    "    ds_lsb_test.save('lsb_test')\n",
    "    ds_msb_test.save('msb_test')\n",
    "\n",
    "print(\"Data imported\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netword trained\n"
     ]
    }
   ],
   "source": [
    "wsd_lsb.train(X_traincv_lsb, y_traincv)\n",
    "wsd_msb.train(X_traincv_msb, y_traincv)\n",
    "\n",
    "print(\"Netword trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing...\")\n",
    "\n",
    "out = []\n",
    "for i in range(len(X_testcv_lsb)):\n",
    "    print(i)\n",
    "    out_lsb    = wsd_lsb.classify([X_testcv_lsb[i]])\n",
    "    out_msb    = wsd_msb.classify([X_testcv_msb[i]])\n",
    "    expiro = 0\n",
    "    neshta = 0\n",
    "    sality = 0\n",
    "    vba = 0\n",
    "    for j in range(4): # \"Expiro\",\"Neshta\",\"Sality\",\"VBA\"\n",
    "        if out_lsb[0]['classesDegrees'][j]['class'] == 'Expiro':\n",
    "            expiro += out_lsb[0]['classesDegrees'][j]['degree']\n",
    "        elif out_lsb[0]['classesDegrees'][j]['class'] == 'Neshta':\n",
    "            neshta += out_lsb[0]['classesDegrees'][j]['degree']\n",
    "        elif out_lsb[0]['classesDegrees'][j]['class'] == 'Sality':\n",
    "            sality += out_lsb[0]['classesDegrees'][j]['degree']\n",
    "        elif out_lsb[0]['classesDegrees'][j]['class'] == 'VBA':\n",
    "            vba += out_lsb[0]['classesDegrees'][j]['degree']\n",
    "        if out_msb[0]['classesDegrees'][j]['class'] == 'Expiro':\n",
    "            expiro += out_msb[0]['classesDegrees'][j]['degree']\n",
    "        elif out_msb[0]['classesDegrees'][j]['class'] == 'Neshta':\n",
    "            neshta += out_msb[0]['classesDegrees'][j]['degree']\n",
    "        elif out_msb[0]['classesDegrees'][j]['class'] == 'Sality':\n",
    "            sality += out_msb[0]['classesDegrees'][j]['degree']\n",
    "        elif out_msb[0]['classesDegrees'][j]['class'] == 'VBA':\n",
    "            vba += out_msb[0]['classesDegrees'][j]['degree']\n",
    "    results = [expiro, neshta, sality, vba]\n",
    "    largest = max(results)\n",
    "    if results.index(largest) == 0:\n",
    "        out.append('Expiro')\n",
    "    elif results.index(largest) == 1:\n",
    "        out.append('Neshta')\n",
    "    elif results.index(largest) == 2:\n",
    "        out.append('Sality')\n",
    "    elif results.index(largest) == 3:\n",
    "        out.append('VBA')\n",
    "\n",
    "print(\"Tests done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(out):\n",
    "    if out[i] == y_testcv[i]:\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
